{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6016796f",
   "metadata": {},
   "source": [
    "# HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dbccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 35\n",
    "\n",
    "import requests\n",
    "\n",
    "api_key = 'e151956884a8aad1a198c393993f9b1a'\n",
    "city = 'London'\n",
    "endpoint = 'http://api.openweathermap.org/data/2.5/onecall'\n",
    "\n",
    "parameters = {\n",
    "    'lat': 22.380341,\n",
    "    'lon': 114.141296,\n",
    "    'appid': api_key,\n",
    "    'exclude': 'current,minutely,daily'\n",
    "}\n",
    "\n",
    "response = requests.get(url = endpoint, params = parameters)\n",
    "response.raise_for_status()\n",
    "print(response.status_code)\n",
    "\n",
    "data = response.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c816252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_slice = data['hourly']\n",
    "\n",
    "will_rain = False\n",
    "\n",
    "for hour in weather_slice:\n",
    "    condition = hour['weather'][0]['id']\n",
    "    if condition < 700:\n",
    "        will_rain = True\n",
    "        \n",
    "    if will_rain:\n",
    "        print('Bring umbrella')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2287d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 36\n",
    "\n",
    "import requests\n",
    "import datetime as dt\n",
    "\n",
    "STOCK = \"TSLA\"\n",
    "COMPANY_NAME = \"Tesla Inc\"\n",
    "key = 'ZN8XKDN7Z4JX2GP2'\n",
    "\n",
    "## STEP 1: Use https://www.alphavantage.co\n",
    "# When STOCK price increase/decreases by 5% between yesterday and the day before yesterday then print(\"Get News\").\n",
    "\n",
    "url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={STOCK}&apikey={key}'\n",
    "r = requests.get(url)\n",
    "r.raise_for_status\n",
    "print(r.status_code)\n",
    "data = r.json()\n",
    "\n",
    "yesterday = dt.datetime.now().date() - dt.timedelta(days = 1)\n",
    "before_yesterday = yesterday - dt.timedelta(days = 1)\n",
    "yesterday_price = float(data['Time Series (Daily)'][f'{yesterday}']['4. close'])\n",
    "before_yesterday_price = float(data['Time Series (Daily)'][f'{before_yesterday}']['4. close'])\n",
    "\n",
    "key2 = '1342fe0ad34a41538d77eb7bf4abdec0'\n",
    "url2 = f'https://newsapi.org/v2/everything?q=tesla&from={str(before_yesterday)}&sortBy=publishedAt&apiKey={key2}'\n",
    "r2 = requests.get(url2)\n",
    "data2 = r2.json()\n",
    "    \n",
    "## STEP 2: Use https://newsapi.org\n",
    "# Instead of printing (\"Get News\"), actually get the first 3 news pieces for the COMPANY_NAME. \n",
    "\n",
    "volatility = abs(yesterday_price - before_yesterday_price)/yesterday_price\n",
    "news = data2['articles'][:3]\n",
    "if volatility >= 0.05:\n",
    "    for articles in news:\n",
    "        print(news['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 3: Use https://www.twilio.com\n",
    "# Send a seperate message with the percentage change and each article's title and description to your phone number. \n",
    "headline = [news['title'] for headline in news]\n",
    "brief = [news['description'] for brief in news]\n",
    "\n",
    "#Optional: Format the SMS message like this: \n",
    "\"\"\"\n",
    "TSLA: ðŸ”º2%\n",
    "Headline: Were Hedge Funds Right About Piling Into Tesla Inc. (TSLA)?. \n",
    "Brief: We at Insider Monkey have gone over 821 13F filings that hedge funds and prominent investors are required to file by the SEC The 13F filings show the funds' and investors' portfolio positions as of March 31st, near the height of the coronavirus market crash.\n",
    "or\n",
    "\"TSLA: ðŸ”»5%\n",
    "Headline: Were Hedge Funds Right About Piling Into Tesla Inc. (TSLA)?. \n",
    "Brief: We at Insider Monkey have gone over 821 13F filings that hedge funds and prominent investors are required to file by the SEC The 13F filings show the funds' and investors' portfolio positions as of March 31st, near the height of the coronavirus market crash.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd43896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 37\n",
    "\n",
    "pixela_endpoint = 'https://pixe.la/v1/users'\n",
    "\n",
    "user_para = {}\n",
    "\n",
    "r = requests.post(url = pixela_endpoint, json = user_para)\n",
    "r.raise_for_status()\n",
    "data = r.json()\n",
    "\n",
    "graph_endpoint = ''\n",
    "graph_para = {}\n",
    "headers = {'token': token}\n",
    "\n",
    "graph_response = requests.post(url = graph_endpoint, json = graph_para, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.put(url = endpoint, json = parameters, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d150ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 38\n",
    "\n",
    "import requests\n",
    "\n",
    "APP_ID = '4ee99a63'\n",
    "API_KEY = 'e98bf288ee365492d6368d25b3653c63'\n",
    "endpoint = 'https://trackapi.nutritionix.com/v2/natural/exercise'\n",
    "\n",
    "entry = input('Tell me which exercises you did: ')\n",
    "\n",
    "headers = {\n",
    "    'x-app-id': APP_ID,\n",
    "    'x-app-key': API_KEY,\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    'query': entry,\n",
    "    'gender': 'male',\n",
    "    'weight_kg': 75,\n",
    "    'height_cm': 180,\n",
    "    'age': 27,\n",
    "}\n",
    "\n",
    "r = requests.post(endpoint, json = parameters, headers = headers)\n",
    "print(r.raise_for_status(), r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20103898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "endpoint = 'https://api.sheety.co/phill/workout/Workout'\n",
    "today = dt.datetime.now()\n",
    "date = today.strftime('%d/%m/%Y')\n",
    "time = today.strftime('%H:%M:%S')\n",
    "\n",
    "def add_row(exercise, duration, calories):\n",
    "\n",
    "    info = {\n",
    "        'Workout': {\n",
    "            'Date': date,\n",
    "            'Time': time,\n",
    "            'Exercise': exercise,\n",
    "            'Duration': duration,\n",
    "            'Calories': calories,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    r = requests.post(endpoint, json = info, headers = headers)\n",
    "\n",
    "for exercise in data['exercises']:\n",
    "    add_row(exercise['exercise'], exercise['duration'], exercise['calories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f2e92",
   "metadata": {},
   "source": [
    "# BeautifulSoup/HTTP Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e3589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 45\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "with open ('website.html', 'rb') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# can use lxml or html.parser to parse html contents\n",
    "soup = BeautifulSoup(content, 'lxml')\n",
    "print(soup.title)\n",
    "print(soup.title.name)\n",
    "print(soup.title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28430c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidy up printed text\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22edcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_anchor_tags = soup.find_all(name = 'a')\n",
    "\n",
    "for tag in all_anchor_tags:\n",
    "    print(tag.getText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39043ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(name = 'h1', id = 'name')\n",
    "soup.find(name = 'h3', class_ = 'heading').string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaa1c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select_one(selector = '#name')\n",
    "soup.select_one(selector = '.heading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(url = 'https://news.ycombinator.com/')\n",
    "print(r.status_code)\n",
    "r.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b16bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage = r.text\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "articles = soup.find_all(name = 'a', class_ = 'storylink')\n",
    "\n",
    "article_text = []\n",
    "article_link = []\n",
    "for article_tag in articles:\n",
    "    text = article_tag.getText()\n",
    "    article_text.append(text)\n",
    "    link = article_tag.get('href')\n",
    "    article_link.append(link)\n",
    "\n",
    "article_upvote = [int(score.getText().replace(' points', '')) for score in soup.find_all(name = 'span', class_ = 'score')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3826ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = soup.find_all(name = 'h3', class_ = 'jsx-4245974604')\n",
    "movies_list = [movie.getText() for movie in reversed(movies)]\n",
    "\n",
    "with open('movies.txt', 'wb') as f:\n",
    "    for movie in movies_list:\n",
    "        f.write(f'{movie}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df02004",
   "metadata": {},
   "source": [
    "# Webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 48\n",
    "from selenium import webdriver\n",
    "\n",
    "chrome_driver_path = '/Users/ching/chromedriver'\n",
    "driver = webdriver.Chrome(executable_path = chrome_driver_path)\n",
    "url = 'https://www.python.org/'\n",
    "driver.get(url)\n",
    "#price = driver.find_element_by_id('priceblock_ourprice')\n",
    "#name = driver.find_element_by_name('search_query')\n",
    "#item = driver.find_element_by_class_name('python-logo')\n",
    "#documentation_link = driver.find_element_by_css_selector('.tier-1 element-7 a')\n",
    "#link = driver.find_element_by_xpath('//*[@id=\"site-map\"]/div[2]/div/ul/li[3]/a')\n",
    "#events = driver.find_elements_by_class_name('shrubbery')\n",
    "event_time = driver.find_elements_by_css_selector('.event-widget time')\n",
    "event = driver.find_elements_by_css_selector('.event-widget li a')\n",
    "events = {e.text: time.text for e in event for time in event_time}\n",
    "print(events)\n",
    "\n",
    "#for time in event:\n",
    "#    print(time.text)\n",
    "driver.quit()\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc4b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "driver.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "#c = driver.find_element_by_css_selector('#articlecount a')\n",
    "#all_portals = driver.find_element_by_link_text('All portals')\n",
    "#all_portals.click()\n",
    "search = driver.find_element_by_name('search')\n",
    "search.send_keys('python')\n",
    "search.send_keys(Keys.ENTER)\n",
    "#print(c.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "driver.get('https://secure-retreat-92358.herokuapp.com/')\n",
    "fname = driver.find_element_by_name('fName')\n",
    "fname.send_keys('Angela')\n",
    "lname = driver.find_element_by_name('lName')\n",
    "lname.send_keys('Yu')\n",
    "email = driver.find_element_by_name('email')\n",
    "email.send_keys('abc@gmail.com')\n",
    "click = driver.find_element_by_css_selector('form button')\n",
    "click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2545a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "chrome_driver_path = '/Users/ching/chromedriver'\n",
    "url = 'https://orteil.dashnet.org/cookieclicker/'\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "driver.get(url)\n",
    "\n",
    "cookie = driver.find_element_by_id('bigCookie')\n",
    "\n",
    "while True:\n",
    "    cookie.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefab591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 49\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "path = '/Users/ching/chromedriver'\n",
    "driver = webdriver.Chrome(executable_path=path)\n",
    "url = 'https://www.linkedin.com/jobs/search/?f_LF=f_AL&geoId=102257491&keywords=python%20developer&location=London%2C%20England%2C%20United%20Kingdom&redirect=false&position=1&pageNum=0'\n",
    "driver.get(url)\n",
    "\n",
    "\"\"\"\n",
    "# auto login\n",
    "login_page = 'https://www.linkedin.com/login/en?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin'\n",
    "email = driver.find_element_by_id(id = 'username')\n",
    "password = driver.find_element_by_id(id = 'password')\n",
    "email.send_keys('email')\n",
    "password.send_keys('password')\n",
    "password.send_keys(Keys.ENTER)\n",
    "sleep(7)\n",
    "\"\"\"\n",
    "\n",
    "# apply for jobs\n",
    "\n",
    "is_job = True\n",
    "while is_job:\n",
    "    try:\n",
    "        job = driver.find_elements_by_css_selector('.div href')\n",
    "        for _ in job:\n",
    "            button = driver.find_element_by_class_name('.jobs-s-apply button')\n",
    "            button.click()\n",
    "            mobile = driver.find_element_by_class_name('ember-text-field ember-view fb-single-line-text__input')\n",
    "            mobile.send_keys('mobile number')\n",
    "            button = driver.find_elements_by_css_selector('.footter button')\n",
    "            button.click()\n",
    "        section = driver.find_element_by_css_selector('.section button')\n",
    "    except NoSuchElementException:\n",
    "        continue\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ffdf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 53\n",
    "\n",
    "form_url = 'https://forms.gle/Tvcc3uJbeKaGqNry5'\n",
    "driver = webdriver.Chrome(executable_path=path)\n",
    "driver.get('https://www.zillow.com/homes/for_rent/1-_beds/?searchQueryState=%7B%22mapBounds%22%3A%7B%22west%22%3A-122.90711440039063%2C%22east%22%3A-121.95954359960938%2C%22south%22%3A37.479997952295%2C%22north%22%3A38.06941019642464%7D%2C%22isMapVisible%22%3Afalse%2C%22filterState%22%3A%7B%22price%22%3A%7B%22max%22%3A872627%7D%2C%22beds%22%3A%7B%22min%22%3A1%7D%2C%22fore%22%3A%7B%22value%22%3Afalse%7D%2C%22mp%22%3A%7B%22max%22%3A3000%7D%2C%22auc%22%3A%7B%22value%22%3Afalse%7D%2C%22nc%22%3A%7B%22value%22%3Afalse%7D%2C%22fr%22%3A%7B%22value%22%3Atrue%7D%2C%22fsbo%22%3A%7B%22value%22%3Afalse%7D%2C%22cmsn%22%3A%7B%22value%22%3Afalse%7D%2C%22fsba%22%3A%7B%22value%22%3Afalse%7D%7D%2C%22isListVisible%22%3Atrue%7D')\n",
    "page = 2\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        price = driver.find_elements_by_class_name('list-card-price')\n",
    "        address = driver.find_elements_by_class_name('list-card-addr')\n",
    "        link = driver.find_elements_by_css_selector('.list-card-info a')\n",
    "    except NoSuchElementException:\n",
    "        print('No such element!')\n",
    "        try:\n",
    "            next_page = driver.find_element_by_xpath(f'//*[@id=\"grid-search-results\"]/div[2]/nav/ul/li[f{page}]/a')\n",
    "            page += 1\n",
    "        except NoSuchElementException:\n",
    "            print('No such element!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf7df0e",
   "metadata": {},
   "source": [
    "# Decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9242261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python decorator\n",
    "from time import sleep\n",
    "\n",
    "def delay_decorator(function):\n",
    "    def wrapper_function():\n",
    "        sleep(2)\n",
    "        # do sth before\n",
    "        function()\n",
    "        function()\n",
    "        # do sth after\n",
    "    return wrapper_function\n",
    "\n",
    "@delay_decorator\n",
    "def say_hello():\n",
    "    print('Hello')\n",
    "    \n",
    "@delay_decorator\n",
    "def say_goodbye():\n",
    "    print('Goodbye')\n",
    "    \n",
    "def say_greeting():\n",
    "    print('How are you?')\n",
    "    \n",
    "decorated_function = delay_decorator(say_greeting)\n",
    "decorated_function()\n",
    "    \n",
    "#say_hello()\n",
    "#say_goodbye()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
